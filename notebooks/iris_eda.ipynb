{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75491fc",
   "metadata": {},
   "source": [
    "# Iris Dataset - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis on the Iris dataset for our MLOps pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d25ce",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFeature names:\", iris.feature_names)\n",
    "print(\"\\nTarget names:\", iris.target_names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nDataset Description:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81851a8",
   "metadata": {},
   "source": [
    "## 2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24eb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Iris Dataset - Feature Distributions by Species', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot distributions for each feature\n",
    "features = iris.feature_names\n",
    "for i, feature in enumerate(features):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    for species in df['species'].unique():\n",
    "        subset = df[df['species'] == species]\n",
    "        axes[row, col].hist(subset[feature], alpha=0.7, label=species, bins=15)\n",
    "    \n",
    "    axes[row, col].set_title(feature.replace(' (cm)', '').title(), fontweight='bold')\n",
    "    axes[row, col].set_xlabel('Value (cm)')\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "    axes[row, col].legend()\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for each feature\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Iris Dataset - Feature Box Plots by Species', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    sns.boxplot(data=df, x='species', y=feature, ax=axes[row, col])\n",
    "    axes[row, col].set_title(feature.replace(' (cm)', '').title(), fontweight='bold')\n",
    "    axes[row, col].set_xlabel('Species')\n",
    "    axes[row, col].set_ylabel('Value (cm)')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c455269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df, hue='species', height=2.5)\n",
    "plt.suptitle('Iris Dataset - Pairwise Feature Relationships', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988adb54",
   "metadata": {},
   "source": [
    "## 3. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary by species\n",
    "print(\"Statistical Summary by Species:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for species in df['species'].unique():\n",
    "    print(f\"\\n{species.upper()}:\")\n",
    "    subset = df[df['species'] == species][features]\n",
    "    print(subset.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis using simple variance\n",
    "feature_variance = df[features].var().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(range(len(feature_variance)), feature_variance.values)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Feature Variance Analysis', fontweight='bold')\n",
    "plt.xticks(range(len(feature_variance)), \n",
    "           [name.replace(' (cm)', '') for name in feature_variance.index], \n",
    "           rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature Variance Ranking:\")\n",
    "for i, (feature, variance) in enumerate(feature_variance.items(), 1):\n",
    "    print(f\"{i}. {feature}: {variance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912f937",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea17236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "\n",
    "# Check class distribution in splits\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "train_dist = pd.Series(y_train).value_counts().sort_index()\n",
    "for i, count in enumerate(train_dist):\n",
    "    print(f\"Class {i} ({iris.target_names[i]}): {count}\")\n",
    "\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "test_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "for i, count in enumerate(test_dist):\n",
    "    print(f\"Class {i} ({iris.target_names[i]}): {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling demonstration\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Compare before and after scaling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Before scaling\n",
    "axes[0].boxplot([X_train[col] for col in X_train.columns], \n",
    "                labels=[col.replace(' (cm)', '') for col in X_train.columns])\n",
    "axes[0].set_title('Before Scaling', fontweight='bold')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# After scaling\n",
    "axes[1].boxplot([X_train_scaled[:, i] for i in range(X_train_scaled.shape[1])], \n",
    "                labels=[col.replace(' (cm)', '') for col in X_train.columns])\n",
    "axes[1].set_title('After Scaling', fontweight='bold')\n",
    "axes[1].set_ylabel('Scaled Value')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Scaling Statistics:\")\n",
    "print(f\"Original data - Mean: {X_train.mean().values}\")\n",
    "print(f\"Original data - Std: {X_train.std().values}\")\n",
    "print(f\"Scaled data - Mean: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"Scaled data - Std: {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee2d4f1",
   "metadata": {},
   "source": [
    "## 5. Key Insights\n",
    "\n",
    "### Dataset Characteristics:\n",
    "- **Size**: 150 samples, 4 features\n",
    "- **Classes**: 3 balanced classes (50 samples each)\n",
    "- **Missing Values**: None\n",
    "- **Feature Types**: All numerical (continuous)\n",
    "\n",
    "### Feature Analysis:\n",
    "- **Petal length** shows the highest variance and best separability\n",
    "- **Petal width** also shows good class separation\n",
    "- **Sepal features** have more overlap between classes\n",
    "- Features are positively correlated, especially petal measurements\n",
    "\n",
    "### Class Separability:\n",
    "- **Setosa** is clearly separable from other classes\n",
    "- **Versicolor** and **Virginica** have some overlap\n",
    "- Petal measurements are most discriminative\n",
    "\n",
    "### Preprocessing Needs:\n",
    "- Features have different scales - standardization recommended\n",
    "- No missing values to handle\n",
    "- Balanced classes - no resampling needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data for use in the pipeline\n",
    "import os\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "# Save raw data\n",
    "df.to_csv('../data/iris_raw.csv', index=False)\n",
    "print(\"Raw data saved to '../data/iris_raw.csv'\")\n",
    "\n",
    "# Save processed data\n",
    "np.save('../data/X_train.npy', X_train_scaled)\n",
    "np.save('../data/X_test.npy', X_test_scaled)\n",
    "np.save('../data/y_train.npy', y_train.values)\n",
    "np.save('../data/y_test.npy', y_test.values)\n",
    "print(\"Processed data saved to '../data/' directory\")\n",
    "\n",
    "print(\"\\nEDA completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
